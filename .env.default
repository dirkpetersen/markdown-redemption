# ============================================================================
# The Markdown Redemption - Configuration Template
# ============================================================================
# Copy this file to .env and customize the values below.
# DO NOT commit .env to version control - it may contain secrets!

# ----------------------------------------------------------------------------
# Flask Application Settings
# ----------------------------------------------------------------------------

# Environment mode: development or production
FLASK_ENV=development

# Secret key for session signing - CHANGE THIS IN PRODUCTION!
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
SECRET_KEY=change-this-to-a-random-secret-key-in-production

# Server binding
HOST=0.0.0.0
PORT=5000

# Debug mode - MUST be False in production
DEBUG=True

# ----------------------------------------------------------------------------
# Application Identity
# ----------------------------------------------------------------------------

APP_NAME=The Markdown Redemption
APP_TAGLINE=Every document deserves a second chance
THEME_COLOR=#D73F09

# ----------------------------------------------------------------------------
# File Upload Configuration
# ----------------------------------------------------------------------------

# Maximum file size in bytes (default: 100MB)
MAX_UPLOAD_SIZE=104857600

# Temporary storage directories
UPLOAD_FOLDER=uploads
RESULT_FOLDER=results

# Allowed file extensions (comma-separated)
ALLOWED_EXTENSIONS=jpg,jpeg,png,gif,bmp,webp,pdf,docx

# Maximum number of files per upload batch
MAX_CONCURRENT_UPLOADS=100

# ----------------------------------------------------------------------------
# LLM API Configuration
# ----------------------------------------------------------------------------

# OpenAI-compatible API endpoint
# For Ollama: http://localhost:11434/v1
# For remote server: http://192.168.1.100:8000/v1
# The /v1 path will be added automatically if missing
LLM_ENDPOINT=http://localhost:11434/v1

# Model identifier (e.g., qwen2.5vl:latest, gpt-4-vision-preview)
LLM_MODEL=qwen/qwen3-VL-30b-a3b-instruct

# API key/token (optional for local models, required for OpenAI)
LLM_API_KEY=

# Request timeout in seconds
LLM_TIMEOUT=120

# ----------------------------------------------------------------------------
# Automatic Cleanup Configuration
# ----------------------------------------------------------------------------

# Number of hours after which temporary files are deleted
CLEANUP_HOURS=24

# Enable/disable automatic cleanup
ENABLE_AUTO_CLEANUP=True

# ----------------------------------------------------------------------------
# Document Processing Options
# ----------------------------------------------------------------------------

# PDF rendering quality multiplier (2.0 = ~144 DPI)
PDF_DPI_SCALE=2.0

# Markdown separator between PDF pages
PDF_PAGE_SEPARATOR=---

# ZIP compression level (0-9, where 9 is maximum compression)
ZIP_COMPRESSION_LEVEL=9

# ----------------------------------------------------------------------------
# Advanced Options
# ----------------------------------------------------------------------------

# Custom extraction prompt (leave empty to use default)
EXTRACTION_PROMPT=

# Enable verbose logging for debugging
VERBOSE_LOGGING=False

# Save intermediate rendered images for troubleshooting
SAVE_DEBUG_IMAGES=False

# ----------------------------------------------------------------------------
# Session Configuration
# ----------------------------------------------------------------------------

# Session type: filesystem (recommended) or default (cookie-based)
SESSION_TYPE=filesystem

# Directory for server-side session storage
SESSION_FILE_DIR=flask_session

# Session lifetime in seconds (default: 24 hours)
SESSION_PERMANENT=False
PERMANENT_SESSION_LIFETIME=86400
